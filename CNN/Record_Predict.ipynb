{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class CNN1(nn.Module): # 更換模型\n",
    "  def __init__(self, n_chan=32):\n",
    "    super().__init__()\n",
    "    self.n_chan = n_chan\n",
    "    self.conv1 = nn.Conv2d(4, n_chan, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(n_chan, n_chan//2, kernel_size=3, padding=1)\n",
    "    self.fc1 = nn.Linear(n_chan//2 * 90 * 90, 32)\n",
    "    self.fc2 = nn.Linear(32, 6)\n",
    "\n",
    "  def forward(self, out):\n",
    "    out = F.max_pool2d(F.relu(self.conv1(out)), 2)\n",
    "    out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "    out = out.view(-1, self.n_chan//2 * 90 * 90)\n",
    "    out = F.relu(self.fc1(out))\n",
    "    out = self.fc2(out)\n",
    "    return out\n",
    " \n",
    "mean = [0.3740, 0.3766, 0.3755, 0.3776]\n",
    "std = [0.4429, 0.4416, 0.4419, 0.4407]\n",
    "preprocess = transforms.Compose([ # 更換正規化參數\n",
    "  transforms.Resize([360, 360]), # 更換圖片輸入大小\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "def data_loader(file_path):\n",
    "    image = Image.open(file_path)\n",
    "    image_tensor = preprocess(image)\n",
    "    return image_tensor\n",
    "\n",
    "label_dict = {\"front\":0, \"back\":1, \"left\":2, \"right\":3, \"up\":4, \"down\":5}\n",
    "inv_label_dict = [key for key in label_dict.keys()]\n",
    "print(inv_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# WAV成生圖片\n",
    "def PlotFreq_Time(fileName): # 更換畫圖的function\n",
    "    output_path = fileName.split('.')[0] + \".png\"\n",
    "    audio_data, sample_rate = librosa.load(fileName)\n",
    "    stft = librosa.stft(audio_data)\n",
    "    spectrogram = librosa.amplitude_to_db(abs(stft))\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    librosa.display.specshow(spectrogram, sr=sample_rate, cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def SoundPredict(_model, _modelPath, _imgPath):\n",
    "    model = _model\n",
    "    model.load_state_dict(torch.load(_modelPath))\n",
    "    model.eval()\n",
    "    imgs= data_loader(_imgPath)\n",
    "    imgs= imgs.unsqueeze(0)\n",
    "    outputs= model(imgs)\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    print(inv_label_dict[predicted.item()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "# pip install sounddevice\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "freq = 44100\n",
    "duration = 2 # 錄音持續 2 秒\n",
    "MODEL_PATH = \"model1.pth\"\n",
    "\n",
    "# 執行 且 print \"start\" 後 開始錄音2秒，並預測\n",
    "recording = sd.rec(int(duration*freq), samplerate=freq, channels=2)\n",
    "print(\"start\")\n",
    "sd.wait()\n",
    "wavfile.write(\"output.wav\", freq, recording)\n",
    "PlotFreq_Time(\"output.wav\")\n",
    "SoundPredict(CNN1(), MODEL_PATH, \"output.png\") #更改使用的模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
