{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR_WAV = \"Dataset_wav\\\\\"\n",
    "DIR_PNG = \"Dataset_png\\\\\"\n",
    " \n",
    "def PlotFreq_Time(rFolder, sFolder, name):\n",
    "    source_path = rFolder + name\n",
    "    output_path = sFolder + name.split('.')[0] + \".png\"\n",
    "    if not os.path.exists(output_path):\n",
    "        audio_data, sample_rate = librosa.load(source_path)\n",
    "        stft = librosa.stft(audio_data)\n",
    "        spectrogram = librosa.amplitude_to_db(abs(stft))\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        librosa.display.specshow(spectrogram, sr=sample_rate, cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "pre_NoNorm = transforms.Compose([\n",
    "    transforms.Resize((360, 360)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "def loaderNoNorm(folder, name):\n",
    "    img = Image.open(folder + name)\n",
    "    img_t = pre_NoNorm(img)\n",
    "    return img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([840]), torch.Size([360]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading all WAV file and convert to PNG\n",
    "all_WAV_Names = [file for file in os.listdir(DIR_WAV) if file.endswith(\".wav\")]\n",
    "for name in all_WAV_Names:\n",
    "    PlotFreq_Time(DIR_WAV, DIR_PNG, name)\n",
    "\n",
    "# Generating random train and valid indexs\n",
    "n_Datas = len(all_WAV_Names)\n",
    "n_valid = int(0.3*n_Datas)\n",
    "shuffled_indexs = torch.randperm(n_Datas)\n",
    "tra_indexs = shuffled_indexs[n_valid:]\n",
    "val_indexs = shuffled_indexs[:n_valid]\n",
    "tra_indexs.shape, val_indexs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3463, 0.3521, 0.3502, 0.3516]) tensor([0.4564, 0.4546, 0.4549, 0.4546])\n",
      "tensor([0.3446, 0.3485, 0.3468, 0.3533]) tensor([0.4567, 0.4557, 0.4560, 0.4541])\n"
     ]
    }
   ],
   "source": [
    "# Loading train and valid PNG file and calculate the std and mean\n",
    "all_PNG_Names = [file for file in os.listdir(DIR_PNG) if file.endswith(\".png\")]\n",
    "tra_PNG_Names = [all_PNG_Names[index] for index in tra_indexs]\n",
    "val_PNG_Names = [all_PNG_Names[index] for index in val_indexs]\n",
    "tra_imgs = torch.stack([loaderNoNorm(DIR_PNG, name) for name in tra_PNG_Names])\n",
    "val_imgs = torch.stack([loaderNoNorm(DIR_PNG, name) for name in val_PNG_Names])\n",
    "tra_mean = tra_imgs.view(4, -1).mean(dim=1)\n",
    "tra_std = tra_imgs.view(4, -1).std(dim=1)\n",
    "val_mean = val_imgs.view(4, -1).mean(dim=1)\n",
    "val_std = val_imgs.view(4, -1).std(dim=1)\n",
    "print(tra_mean, tra_std)\n",
    "print(val_mean, val_std)\n",
    "label_dict = {\"front\":0, \"back\":1, \"left\":2, \"right\":3, \"up\":4, \"down\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building train and valid preprocess\n",
    "tra_preprocess = transforms.Compose([\n",
    "  transforms.Resize([360, 360]),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=tra_mean, std=tra_std)\n",
    "])\n",
    "val_preprocess = transforms.Compose([\n",
    "  transforms.Resize([360, 360]),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=tra_mean, std=tra_std)\n",
    "])\n",
    "def tra_loader(path):\n",
    "  img = Image.open(path)\n",
    "  img_t = tra_preprocess(img)\n",
    "  return img_t\n",
    "def val_loader(path):\n",
    "  img = Image.open(path)\n",
    "  img_t = val_preprocess(img)\n",
    "  return img_t\n",
    "\n",
    "# Using in categorizing label by PNG name\n",
    "import re\n",
    "def removeNum(s):\n",
    "    return re.sub(r'\\d+|\\..*', '', s)\n",
    "# Some Data the Dataset need\n",
    "tra_PNG_Paths = [DIR_PNG + name for name in tra_PNG_Names]\n",
    "tra_PNG_Label = torch.tensor([label_dict[removeNum(name)] for name in tra_PNG_Names])\n",
    "val_PNG_Paths = [DIR_PNG + name for name in val_PNG_Names]\n",
    "val_PNG_Label = torch.tensor([label_dict[removeNum(name)] for name in val_PNG_Names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Custom DataSet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VoiceDataSet(Dataset):\n",
    "  def __init__(self, isTrain = True):\n",
    "    self.paths = tra_PNG_Paths if isTrain else val_PNG_Paths\n",
    "    self.labels = tra_PNG_Label if isTrain else val_PNG_Label\n",
    "    self.loader = tra_loader if isTrain else val_loader\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.paths)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    path = self.paths[index]\n",
    "    image = self.loader(path)\n",
    "    label = self.labels[index]\n",
    "    return image, label\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Accuracy calculation function\n",
    "def Accuracy(model, tra_loader, val_loader):\n",
    "  result = {}\n",
    "  model.eval()\n",
    "  for name, loader in [(\"train\", tra_loader),(\"valid\", val_loader)]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      for imgs, labels in loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total+= labels.shape[0]\n",
    "        correct+= int((predicted==labels).sum())\n",
    "    result[name] = correct / total\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Setting the CNN module\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, n_chan=32):\n",
    "    super().__init__()\n",
    "    self.n_chan = n_chan\n",
    "    self.conv1 = nn.Conv2d(4, n_chan, kernel_size=5, padding=1)\n",
    "    self.conv2 = nn.Conv2d(n_chan, n_chan//2, kernel_size=5, padding=1)\n",
    "    self.fc1 = nn.Linear(n_chan//2 * 88 * 88, 32)\n",
    "    self.fc2 = nn.Linear(32, 6)\n",
    "\n",
    "  def forward(self, out):\n",
    "    print(out.shape)\n",
    "    out = F.max_pool2d(F.relu(self.conv1(out)), 2)\n",
    "    print(out.shape)\n",
    "    out = F.max_pool2d(F.relu(self.conv2(out)), 2)\n",
    "    print(out.shape)\n",
    "    out = out.view(-1, self.n_chan//2 * 88 * 88)\n",
    "    print(out.shape)\n",
    "    out = F.relu(self.fc1(out))\n",
    "    print(out.shape)\n",
    "    out = self.fc2(out)\n",
    "    print(out.shape)\n",
    "    return out\n",
    "  \n",
    "# Setting the training loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fcn, train_loader, valid_loader):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "      loss_train = 0.\n",
    "      loss_valid = 0.\n",
    "      model.train()\n",
    "      for imgs, labels in train_loader:\n",
    "        outputs=model(imgs)\n",
    "        loss=loss_fcn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train+= loss.item()\n",
    "      avg_traLoss = loss_train/len(train_loader)\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        for imgs, labels in valid_loader:\n",
    "          outputs = model(imgs)\n",
    "          loss = loss_fcn(outputs, labels)\n",
    "          loss_valid += loss.item()\n",
    "      avg_valLoss = loss_valid/len(valid_loader)\n",
    "      accuracy = Accuracy(model, train_loader, valid_loader)\n",
    "      print(\"| Epoch: {0:3} | Train_Loss: {1:.4f} | Valid_Loss: {2:.4f} | Train_Accuracy: {3:.4f} | Valid_Accuracy: {4:.4f} |\".format(epoch, avg_traLoss, avg_valLoss, accuracy[\"train\"], accuracy[\"valid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "tra_data = VoiceDataSet(isTrain = True)\n",
    "val_data = VoiceDataSet(isTrain = False)\n",
    "trainLoader = DataLoader(tra_data, batch_size=10, shuffle=True)\n",
    "validLoader = DataLoader(val_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting training\n",
    "model = CNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 5e-4)\n",
    "loss_fcn = nn.CrossEntropyLoss()\n",
    "training_loop(n_epochs = 100, optimizer = optimizer, model = model, loss_fcn = loss_fcn, train_loader = trainLoader, valid_loader=validLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to .pth file\n",
    "filepath = 'model.pth'\n",
    "torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = CNN()\n",
    "model_in.load_state_dict(torch.load(\"model.pth\"))\n",
    "Accuracy(model_in, trainLoader, validLoader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
